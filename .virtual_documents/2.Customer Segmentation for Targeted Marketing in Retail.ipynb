





import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
plt.style.use('fivethirtyeight')


# load the dataset
df = pd.read_excel('Online Retail.xlsx')


def data_summary(df):
    print("📌 Dataset Shape:")
    print(f"Rows: {df.shape[0]}, Columns: {df.shape[1]}")
    print("\n📌 Column-wise Missing Values:")
    missing = df.isnull().sum()
    if missing.any():
        print(missing[missing > 0])
    else:
        print("✅ No missing values found.")
    
    print("\n📌 Duplicate Rows:")
    duplicate_count = df.duplicated().sum()
    if duplicate_count > 0:
        print(f"⚠️ Found {duplicate_count} duplicate rows.")
    else:
        print("✅ No duplicate rows found.")
    
    print("\n📌 Basic Info:")
    print(df.info())

# Call it
data_summary(df)


# display five rows
df.head()








## drop rows with missing values
df = df.dropna(subset=['CustomerID','Description']).copy()

# confirmation
missing_values = df.isnull().sum()
if missing_values.sum() > 0:
    print(missing_values[missing_values>0])
else:
    print('congratulations! ✅ Missing values are Handled Successfully')


# Check and remove duplicates
duplicate_rows = df.duplicated().sum()

if duplicate_rows > 0:
    df.drop_duplicates(inplace=True)
    print('✅ Duplicates removed successfully.')
else:
    print('✅ No duplicate rows found.')



# Clean invalid (<= 0) values in Quantity and UnitPrice columns
df_cleaned = df.copy()  
invalid_columns = ['Quantity', 'UnitPrice']

for col in invalid_columns:
    invalid_values = df_cleaned[df_cleaned[col] <= 0]
    invalid_rows = len(invalid_values)
    print(f"\n🚫 Invalid entries in column '{col}' (<= 0): {invalid_rows} rows\n")
    print("⚠️ Invalid entries are being removed...")

    if invalid_rows >= 0:
        df_cleaned = df_cleaned[df_cleaned[col] > 0].copy()
        print(f"✅ Invalid rows in '{col}' removed successfully.")
        # print(df_cleaned[col].value_counts())
    else:
        print(f"✅ No invalid values found in '{col}'.")



# It must be followed `[0-9]{5}[a-zA-Z]+` pattern
mask = (
    (df_cleaned['StockCode'].str.match('^\\d{5}$')==True) | (df_cleaned['StockCode'].str.match('^\\d{5}[a-zA-Z]+$')==True)
)


df_cleaned = df_cleaned[mask].round(2)


def clean_column_spaces(df_cleaned, column):
    # Count how many values have leading or trailing spaces
    has_spaces = df_cleaned[column].astype(str).apply(lambda x: x != x.strip()).sum()
    
    if has_spaces > 0:
        # Clean the spaces
        df_cleaned[column] = df_cleaned[column].astype(str).str.strip().str.upper()
        print(f"🧹 Column '{column}': Removed leading/trailing spaces from {has_spaces} rows ✅")
    else:
        print(f"✔️ Column '{column}' is already clean. No extra spaces found.")



columns_to_check = df_cleaned.select_dtypes(include='object').columns.tolist()
for col in columns_to_check:
    clean_column_spaces(df_cleaned,col)


print('New Dataset Dimensions after cleaning\n')
print(f"New Dataset Dimesions : {df_cleaned.shape[0]} Rows and {df_cleaned.shape[1]} Columns")





df_cleaned.describe()





import datetime


#  Create snapshot date (we'll assume analysis is on the next day of the last invoice)
snapshot_date = df_cleaned['InvoiceDate'].max() + datetime.timedelta(days=1)


# we need TotalPrice column
df_cleaned['TotalPrice'] = df_cleaned['Quantity'] * df_cleaned['UnitPrice']


rfm = df_cleaned.groupby('CustomerID').agg({
    'InvoiceDate':lambda x : (snapshot_date-x.max()).days,
    'InvoiceNo': 'nunique',
    'TotalPrice':'sum'
}).rename(columns={
    'InvoiceDate':'Recency',
    'InvoiceNo':'Frequency',
    'TotalPrice':'Monetary'
}).reset_index()

print("✅ RFM Table Created Successfully!")
rfm.head()


rfm.describe()








fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(12,8))

# ---------- plot 1------------------
sns.boxplot(data=rfm,y='Recency',color='lightcoral',ax=ax1)
ax1.set_title("Recency Distribution")
ax1.set_xlabel('Recency')
ax1.set_ylabel('')

# ---------- plot 2------------------
sns.boxplot(data=rfm,y='Frequency',color='lightcoral',ax=ax2)
ax2.set_title("Frequency Distribution")
ax2.set_xlabel('Frequency')
ax2.set_ylabel('')
# ---------- plot 1------------------
sns.boxplot(data=rfm,y='Monetary',color='lightcoral',ax=ax3)
ax3.set_title("Monetary Distribution")
ax3.set_xlabel('Monetary')
ax3.set_ylabel('')

plt.tight_layout()
plt.show()
plt.savefig('RFM Distribution of boxplot.png')





def check_outliers(rfm,column):
    q1 = rfm[column].quantile(0.25)
    q3 = rfm[column].quantile(0.75)

    IQR = q3-q1
    
    upper_bound = q3 + 1.5 * IQR
    lower_bound = q1 - 1.5 * IQR

    outliers = rfm[(rfm[column] > upper_bound) | (rfm[column] < lower_bound)]
    print(f'⚠️ Number of Outliers in {column} : {len(outliers)}\n')
    print(outliers.describe())
    print('\n')


columns_to_check_outliers =  ['Frequency','Monetary']
for col in columns_to_check_outliers:
    check_outliers(rfm,col)





def remove_outliers(df, column):
    q1 = df[column].quantile(0.25)
    q3 = df[column].quantile(0.75)
    IQR = q3 - q1

    lower_bound = q1 - 1.5 * IQR
    upper_bound = q3 + 1.5 * IQR

    # Return only the rows that are within the bounds
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]



rfm_cleaned = rfm.copy()

for col in ['Frequency', 'Monetary']:
    rfm_cleaned = remove_outliers(rfm_cleaned, col)






plt.style.use('ggplot')
fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(12,8))

# ---------- plot 1------------------
sns.boxplot(data=rfm_cleaned,y='Recency',color='lightcoral',ax=ax1)
ax1.set_title("Recency Distribution")
ax1.set_xlabel('Recency')
ax1.set_ylabel('')

# ---------- plot 2------------------
sns.boxplot(data=rfm_cleaned,y='Frequency',color='lightcoral',ax=ax2)
ax2.set_title("Frequency Distribution")
ax2.set_xlabel('Frequency')
ax2.set_ylabel('')
# ---------- plot 1------------------
sns.boxplot(data=rfm_cleaned,y='Monetary',color='lightcoral',ax=ax3)
ax3.set_title("Monetary Distribution")
ax3.set_xlabel('Monetary')
ax3.set_ylabel('')

plt.tight_layout()
plt.show()
plt.savefig('RFM Distribution of boxplot.png')





# Score each RFM metric on a scale of 1–5 using quantiles.
rfm_cleaned['R_score'] = pd.qcut(rfm['Recency'], 5, labels=[5,4,3,2,1])
rfm_cleaned['F_score'] = pd.qcut(rfm['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])
rfm_cleaned['M_score'] = pd.qcut(rfm['Monetary'], 5, labels=[1,2,3,4,5])


# Combine RFM Score
rfm_cleaned['RFM_Score'] = rfm_cleaned['R_score'].astype(str) + rfm_cleaned['F_score'].astype(str) + rfm_cleaned['M_score'].astype(str)






def segment_customer(rfm_cleaned):
    r = int(rfm_cleaned['R_score'])
    f = int(rfm_cleaned['F_score'])
    m = int(rfm_cleaned['M_score'])

    if r == 5 and f >= 4 and m >= 4:
        return 'Champions'
    elif r == 5 and f >= 4:
        return 'Loyal Customers'
    elif r == 5:
        return 'Recent Customers'
    elif f >= 4:
        return 'Frequent Buyers'
    elif m >= 4:
        return 'Big Spenders'
    elif r <= 2 and f <= 2:
        return 'At Risk'
    elif r == 1:
        return 'Lost'
    else:
        return 'Others'

rfm_cleaned['Segment'] = rfm_cleaned.apply(segment_customer, axis=1)



rfm_cleaned.head()





# Create figure
fig, ax = plt.subplots(figsize=(18, 12))

# Countplot
sns.countplot(data=rfm_cleaned, y='Segment', palette='YlGn', ax=ax)
ax.set_title('Customer Segmentation Distribution', fontsize=16, fontweight='bold')
ax.set_xlabel('Count')
ax.set_ylabel('Segment')
ax.legend(title='Customer Segmentation', labels=rfm_cleaned['Segment'],loc='lower right')
# Add value labels (count + %)
total = len(rfm_cleaned)
for bar in ax.patches:
    width = bar.get_width()
    percent = (width / total) * 100
    x = width + 2  # little padding
    y = bar.get_y() + bar.get_height() / 2
    ax.text(x, y, f'{int(width)}\n({percent:.1f}%)',
            ha='left', va='center', fontsize=10, fontweight='bold')

# Tidy layout
plt.tight_layout()
plt.show()
plt.savefig('Customer Segmentation Distribution.png')








# Get unique segment names
segments = rfm_cleaned['Segment'].unique()

# Loop through each segment and print the customers
for segment in segments:
    print(f"\n📌 Segment: {segment}")
    segment_customers = rfm_cleaned[rfm_cleaned['Segment'] == segment]
    
    print(f"Total Customers: {len(segment_customers)}")
    print(segment_customers[['CustomerID', 'Recency', 'Frequency', 'Monetary']].head())  # Show first 5 for preview






from sklearn.preprocessing import StandardScaler


# Scale the RFM values
rfm_scaled = rfm_cleaned[['Recency', 'Frequency', 'Monetary']]
scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm_scaled)





from sklearn.cluster import KMeans


## Function to find the optimal number of cluster with elbowmethod
def elbowOptimizer(data):
    wcss = [] # withing cluster sum of cells
    for k in range(1,11):
        kmeans = KMeans(n_clusters=k,random_state=42,init='k-means++')
        kmeans.fit(data)
        wcss.append(kmeans.inertia_) # WCSS score It tells us how tightly grouped the data is within each cluster
    plt.plot(range(1,11), wcss,'bo-')
    plt.title('The Elbow Method')
    plt.xlabel('Number of Clusters (k)')
    plt.ylabel('WCSS')
    plt.show()
    plt.savefig('Elbow Method.png')


elbowOptimizer(rfm_scaled)





import scipy.cluster.hierarchy as sch

# function to find the optimal number of cluster using Dendograms
def dendoOptimizer(data):
    sch.dendrogram(sch.linkage(data,method='ward'))
    plt.title('Dendrogram')
    plt.xlabel('Customers')
    plt.ylabel('Euclidean distances')
    plt.show()
    plt.savefig('Dendrogram.png')


dendoOptimizer(rfm_scaled)








kmeans = KMeans(n_clusters=3, random_state=42)
rfm_cleaned['KMeans_Cluster'] = kmeans.fit_predict(rfm_scaled)


## Analyze the KMeans Cluster
rfm_cleaned.groupby('KMeans_Cluster').agg({
    'Recency':'mean',
    'Frequency':'mean',
    'Monetary':'mean',
    'CustomerID':'count'
}).rename(columns={'CustomerID':'Count',
                  'Recency': 'Average Recency',
                  'Frequency': 'Average Frequency',
                  'Monetary': 'Average Monetary',}).round(1)






# Compare RFM Segments with KMeans Segments
tb = pd.crosstab(rfm_cleaned['Segment'], rfm_cleaned['KMeans_Cluster']).rename(columns=
                                                               {0:'Dorment(0)',
                                                               1:'Light Shoppers(1)',
                                                               2:'Premium Engaged(2)'})


# Set up the heatmap
plt.figure(figsize=(12, 6))
sns.heatmap(tb, annot=True, fmt='d', cmap='YlGnBu', cbar=True, linewidths=0.5)

plt.title('RFM Segment vs KMeans Cluster Mapping', fontsize=16)
plt.xlabel('KMeans Cluster Labels')
plt.ylabel('RFM Segments')
plt.xticks(rotation=0)
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()








from mpl_toolkits.mplot3d import Axes3D


#  Create a 3D Plot
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Plot the clusters in 3D
scatter = ax.scatter(
    rfm_cleaned['Recency'],
    rfm_cleaned['Frequency'],
    rfm_cleaned['Monetary'],
    c=rfm_cleaned['KMeans_Cluster'],
    cmap='Set1',
    s=60,
    alpha=0.7
)

# Label axes
ax.set_xlabel('Recency')
ax.set_ylabel('Frequency')
ax.set_zlabel('Monetary')
ax.set_title('3D Customer Segmentation (RFM + KMeans Clusters)')

# Create custom legend
handles, _ = scatter.legend_elements(prop="colors")
cluster_labels = rfm_cleaned['Cluster_Label'].unique()
legend_labels = [label_map[i] for i in sorted(label_map.keys())]
ax.legend(handles, legend_labels, title="Customer Segments", loc='best')

plt.show()
plt.savefig('3D Customer Segmentation.png')






